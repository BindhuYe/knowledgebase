Summary of the evaluation of the applications

we'll run a couple of benchmarks to compare FastAPI with Node.js on Kubernetes.  First, we'll measure the latency of each request using the 90th percentile, measured from the  client side. Then, we'll measure the throughput of each application by counting how many requests per  second each app can handle. We'll also look at CPU and memory usage, as well as availability or error  rate. And finally, we'll track CPU throttling. In the second, more realistic test, we'll  instrument each app with Prometheus metrics

see how long it takes for each app to  save an item to a relational database, in this case, PostgreSQL 17.2, as well  as to save that data to Memcached. We'll also measure the CPU usage of both  PostgreSQL and Memcached, along with the connection pool size maintained  by each application to the database. I've received a lot of pull  requests since I released the first benchmark, which helped improve both  FastAPI and Node.js applications. I run all my benchmarks on AWS. I have  an EKS cluster using compute-optimized

Graviton instances to run  clients that generate load, plus Grafana and Prometheus. I use m7a.large  instances for the applications themselves, and specialized storage-optimized i8g instances  for PostgreSQL, with m8g for the cache. As you can see, I use a lot of Graviton instances,  which are becoming more and more common. By the way, I have full courses on how to set up a production-level Kubernetes  cluster in AWS, GCP, and Azure. I also use pgtune to optimize my  PostgreSQL to the hardware for this test.

1st Test Alright, let’s go ahead and run the test. I also have a benchmark comparing  FastAPI and Go if you're interested. One of the most important metrics for any client-facing  application is latency. So, in this static test where we return hardcoded objects to the clients,  Node.js performs much better from the start. On the right-hand side, you can see  the number of requests per second, and FastAPI, at around 9,000 requests per  second, started to fall behind. This can mostly be explained by very high CPU usage.  Python is not the most efficient language.

We also have memory usage, but it doesn't  really play any role in this static test. I have a timeout set on the client, and  when the client receives anything other than 200 HTTP status codes, it reduces  the availability of the service. So, in this case, the Python application  started to return failed status codes. And since Python very quickly reached full CPU  usage, it started to be throttled by Kubernetes, which you always need to monitor. This  would be a reason for increased latency and decreased throughput of any  application running in Kubernetes.

So, in this very simple static  test, Python is already very far behind Node.js. Let's run this test until  the Node.js app starts to fail as well. Alright, let me open each graph  for the entire test duration. The test ran for about 1.5 hours, but I  compressed it to just a few minutes. First, we have requests per second. Even  though FastAPI claims it's very close in performance to Go and Node.js, based  on this test, the difference is quite significant. Take a look at a couple  of other tests I ran with FastAPI;

FastAPI only reached 11,000 requests per second  when Node.js reached 50,000 requests per second. Next, we have latency measured by the  90th percentile. Well, in this case, Node.js is also much more stable and performs much  better than FastAPI. Latency is one of the most important metrics, so you should carefully  consider the type of framework you use. Next, we have CPU usage. Python  reached full CPU usage in the first few minutes and started to  degrade from that point forward. Then we have availability or error  rate. It's the ratio of successful

requests divided by the total number of  all requests received by the application. Next, we have memory usage. In this  case, Python also uses much more memory, but it doesn't play any role  in this test. And finally, since we run these applications in  Kubernetes, we need to measure CPU throttling. This happens when the pod tries to  use more CPU than defined in the pod's limit. So, based on this first simple test, we can  conclude that Node.js performs much better, but what about real-world use cases? 2nd Test

In the second test, when each application receives  a POST request, it parses the request body, saves the item to PostgreSQL, and uses cache.  This time, we need to pay attention not only to the overall POST request latency but also  to internal Prometheus metrics to record how long it takes to save an individual item to the  database as well as to save it to Memcached. On the right-hand side, we also measure  the CPU usage of both PostgreSQL and Memcached just to make sure they  are not becoming a bottleneck.

From the start, FastAPI also has much higher  CPU usage, and it could only handle around 2,500 requests per second, which is almost identical to  the previous test with the Go language. I think you get the idea. Let me run this test for a few  more seconds until Node.js starts to fail as well. Let me open each graph for  the entire duration. First, we have requests per second. The difference  is still significant in terms of throughput. Next, we have overall  latency for the POST request. Then, database insert latency.

Next, we have latency for the  set operation for the cache. CPU usage. Database and cache CPU usage. Connection pool size. And finally, we have memory usage. So, this concludes the test. I think it's  clear that Node.js performs much better than FastAPI

